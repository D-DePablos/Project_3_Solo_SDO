{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('solarphysics': conda)"
  },
  "interpreter": {
   "hash": "d0a639d3c126d4e43fb99038fdaa3dc1b98ce2157e3d6dfc89b04e7c34479353"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "BASE_PATH = \"/home/diegodp/Documents/PhD/Paper_3/SolO_SDO_EUI/\"\n",
    "\n",
    "from sys import path\n",
    "\n",
    "path.append(f\"{BASE_PATH}Scripts/\")\n",
    "path.append(f\"/home/diegodp/Documents/PhD/Paper_2/InsituEMDCorrelation/Scripts/EMD/\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import makedirs\n",
    "from EMDComparison import LcurveSolOEMD as lc\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from importsProj3.signalAPI import new_plot_format, plot_super_summary, emdAndCompareCases, caseCreation\n",
    "import idlsave\n",
    "from collections import namedtuple"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### General Setup of lightcurves"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Set the unsafe, target safe, and dataFolder\n",
    "unsafe_dir = \"/home/diegodp/Documents/PhD/Paper_3/SolO_SDO_EUI/unsafe/\"\n",
    "saveFolder = f\"{unsafe_dir}ISSI/New_Method/\"\n",
    "dataFolder = f\"/home/diegodp/Documents/PhD/Paper_3/SolO_SDO_EUI/Scripts/ISSI/data/\"\n",
    "\n",
    "# Parameters for DELETION, showing FIG\n",
    "DELETE = False\n",
    "SHOWFIG = True\n",
    "\n",
    "# We set a large possible set of periodicities\n",
    "PeriodMinMax = [5, 20]\n",
    "makedirs(saveFolder, exist_ok=True)\n",
    "\n",
    "# IN SITU DATA\n",
    "df_is = pd.read_csv(f\"{dataFolder}small_ch_in_situ.csv\")\n",
    "df_is.index = pd.to_datetime(df_is[\"Time\"])\n",
    "del df_is[\"Time\"]\n",
    "\n",
    "insituParams = [\"Vr\", \"Mf\", \"Np\", \"T\", \"Br\"]\n",
    "df_is = df_is[insituParams]\n",
    "\n",
    "# Attempt to read in dataframes\n",
    "try: \n",
    "    df_171 = pd.read_csv(f'{dataFolder}small_ch_171_lc_in.csv', index_col=\"Time\")\n",
    "    df_193 = pd.read_csv(f'{dataFolder}small_ch_193_lc_in.csv', index_col=\"Time\")\n",
    "    df_flux = pd.read_csv(f'{dataFolder}ch_flux.csv', index_col=\"Time\")\n",
    "    print(\"Loaded csv successfully\")\n",
    "\n",
    "    for _df in (df_171, df_193, df_flux):\n",
    "        _df.index = pd.to_datetime(_df.index)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    # REMOTE DATA\n",
    "    rs_171 = idlsave.read(f'{dataFolder}small_ch_171_lc_in.sav', verbose=False)\n",
    "    rs_193 = idlsave.read(f'{dataFolder}small_ch_193_lc_in.sav', verbose=False)\n",
    "    ch_flux = idlsave.read(f'{dataFolder}chflux.sav', verbose=False)\n",
    "\n",
    "    # 171 and 193 observations\n",
    "    time_array = rs_171.date_obs_171.copy()\n",
    "    time_array = [t.decode() for t in list(time_array)]\n",
    "\n",
    "    df_171 = pd.DataFrame(\n",
    "        {\n",
    "            'plume': rs_171.lc_171_plume_in,\n",
    "            'cbpoint': rs_171.lc_171_bp_in,\n",
    "            'chplume': rs_171.lc_171_ch_plume_in,\n",
    "            'chole': rs_171.lc_171_ch_in,\n",
    "            'qsun': rs_171.lc_171_qs_in,\n",
    "        },\n",
    "        index=pd.to_datetime(time_array))\n",
    "\n",
    "\n",
    "    df_193 = pd.DataFrame(\n",
    "        {\n",
    "            'plume': rs_193.lc_193_plume_in,\n",
    "            'cbpoint': rs_193.lc_193_bp_in,\n",
    "            'chplume': rs_193.lc_193_ch_plume_in,\n",
    "            'chole': rs_193.lc_193_ch_in,\n",
    "            'qsun': rs_193.lc_193_qs_in,\n",
    "        },\n",
    "        index=pd.to_datetime(time_array))\n",
    "\n",
    "    # Open and Bright point flux\n",
    "    flux_time = ch_flux.hmitimes.copy()\n",
    "    flux_time = [t.decode() for t in list(flux_time)]\n",
    "\n",
    "    df_flux = pd.DataFrame(\n",
    "        {\n",
    "            \"ch_open_flux\": ch_flux.chofluxes,\n",
    "            \"ch_bpoint_flux\": ch_flux.chbpfluxes,\n",
    "        },\n",
    "        index=pd.to_datetime(flux_time, format=\"%Y.%m.%d_%H:%M:%S_TAI\"))\n",
    "\n",
    "\n",
    "    df_171.to_csv(f'{dataFolder}small_ch_171_lc_in.csv', index_label=\"Time\")\n",
    "    df_193.to_csv(f'{dataFolder}small_ch_193_lc_in.csv', index_label=\"Time\")\n",
    "    df_flux.to_csv(f'{dataFolder}ch_flux.csv', index_label=\"Time\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded csv successfully\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define the API for compareTS"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def combinedPlot(\n",
    "                lcDic=None, \n",
    "                dfPSP=None,\n",
    "                base_folder=None,\n",
    "                PeriodMinMax=[5, 20],\n",
    "                showSpeed=True,\n",
    "                spcSpeeds = (None, None),\n",
    "                regions= None,\n",
    "                superSummary = False,\n",
    "                ):\n",
    "\n",
    "                new_plot_format(\n",
    "                    dfInsitu=dfPSP,\n",
    "                    lcDic=lcDic,\n",
    "                    regions=regions,\n",
    "                    base_folder=base_folder,\n",
    "                    period=PeriodMinMax,\n",
    "                    addResidual = False,\n",
    "                    showSpeed=showSpeed,\n",
    "                    addEMDLcurves = True,\n",
    "                    SPCKernelName = \"psp\",\n",
    "                    spcSpeeds=spcSpeeds,\n",
    "                )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create test cases"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Generate the cases for all possible SolO - SHORT times (every hour)\n",
    "\"\"\"\n",
    "AIACases = {\n",
    "   \"shortTimes\":(datetime(2018, 10, 29, 16), datetime(2018, 10, 30, 23, 50)),\n",
    "   \"longTimes\":(datetime(2018, 10, 31, 8), datetime(2018, 11, 2, 8)),\n",
    "   \"shortDuration\":3,\n",
    "   \"caseName\":\"SDO_AIA\",\n",
    "   \"shortDisplacement\":3,\n",
    "   \"MarginHours\":24,\n",
    "   \"savePicklePath\":\"/home/diegodp/Documents/PhD/Paper_3/SolO_SDO_EUI/Scripts/ISSI/cases/AIAcases.pickle\",\n",
    "   \"forceCreate\": True,\n",
    "}\n",
    "\n",
    "# Get the cases and put them together with respective AIA observations in Dic\n",
    "cases = caseCreation(**AIACases)\n",
    "AIACase = namedtuple(\"AIACase\", [\"name\", \"df\", \"regions\", \"cases\"])\n",
    "LongCase = namedtuple(\"LongCase\", [\"name\", \"df\"])\n",
    "\n",
    "shortDFDic = [AIACase(171, df_171.copy(), df_171.columns, cases), AIACase(193, df_193.copy(), df_193.columns, cases)]\n",
    "longDF = LongCase(\"PSP\", df_is.copy())\n",
    "\n",
    "emdAndCompareCases(shortDFDic, longDF, showFig=True, )\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compare a set of CSV files to created Cases"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def firstCase():\n",
    "    # Selecting ~ 10 hours of in situ observations with 14 switchbacks\n",
    "    timeInsitu = (datetime(2018, 10, 31, 12), datetime(2018, 10, 31, 22))\n",
    "    df_is_cut = df_is[timeInsitu[0]:timeInsitu[1]].copy()\n",
    "\n",
    "    # Time in situ is one hour only?\n",
    "    timeSbs = (datetime(2018,10,30,20), datetime(2018, 10, 30, 21))\n",
    "    df_171_cut = df_171[timeSbs[0]:timeSbs[1]] \n",
    "    df_193_cut = df_193[timeSbs[0]:timeSbs[1]] \n",
    "\n",
    "    lcDic = {\n",
    "        \"171\": df_171_cut.interpolate(),\n",
    "        \"193\": df_193_cut.interpolate(),\n",
    "    }\n",
    "\n",
    "    # Selecting ~ 10 hours of in situ observations\n",
    "    timeInsitu = (datetime(2018, 11, 1, 12), datetime(2018, 11, 1, 20))\n",
    "    df_is_copy = df_is[timeInsitu[0]:timeInsitu[1]].copy()\n",
    "\n",
    "    timeSbs = (datetime(2018,10,30,20), datetime(2018, 10, 30, 21))\n",
    "    df_cut_171 = df_171[timeSbs[0]:timeSbs[1]] \n",
    "    df_cut_193 = df_193[timeSbs[0]:timeSbs[1]] \n",
    "\n",
    "    # This region is not actually highlighted!\n",
    "    highlightRegion =  [{\n",
    "                        \"start\": datetime(2018,10,31,16),\n",
    "                        \"end\": datetime(2018,10,31,20),\n",
    "                        \"color\": \"blue\",\n",
    "                        \"label\": \"SB bmap.\",\n",
    "                        }, ]\n",
    "\n",
    "    for remDF, remLabel in zip((df_cut_171, df_cut_193), (\"171\", \"193\")):\n",
    "        AIA_compare(\n",
    "            AIA=remDF.copy(), PSP=df_is_copy.copy(), AIA_id=remLabel, \n",
    "            PeriodMinMax = PeriodMinMax, delete=DELETE, showFig=SHOWFIG,\n",
    "            subfolderInfo=\"SB_OtherSBs\", showSpeed=True, \n",
    "            highlightRegion = highlightRegion,\n",
    "            LOSPEED=df_is_copy[\"Vr\"].min(), HISPEED = df_is_copy[\"Vr\"].max()\n",
    "            )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Second case with less switchbacks"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Finally, do the photospheric magnetic field case"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open(f\"/home/diegodp/Documents/PhD/Paper_3/SolO_SDO_EUI/Scripts/ISSI/data/HMIcases.pickle\", \"rb\") as f:\n",
    "    import pickle\n",
    "    cases = pickle.load(f)\n",
    "\n",
    "HMItimesList, ISTimesList, caseNamesList, refLocations = lcv.extractDiscreteExamples(\n",
    "    Caselist=cases, \n",
    "    margin=cases[0][\"MARGINHOURSSOLO\"], \n",
    "    AIAduration=4\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO: Think if doing super-summary for AIA as well\n",
    "# Need to compare each of regions in lcDic, df_is\n",
    "# Need to use ISTimesList, HMITimesList, caseNamesList \n",
    "\n",
    "dfIS = (df_is[ISTimesList[0][0]: ISTimesList[0][1]]).resample(f\"{12*60}s\").mean()\n",
    "LOSPEED, HISPEED, AVGSPEED = dfIS[\"Vr\"].min(), dfIS[\"Vr\"].max(), dfIS[\"Vr\"].mean()\n",
    "\n",
    "regLIST = (\"open\", \"bpoint\")\n",
    "\n",
    "def compareHMI():\n",
    "\n",
    "    for index, hmiTimes in enumerate(HMItimesList):\n",
    "        _dffluxCut = df_flux[hmiTimes[0]: hmiTimes[1]]\n",
    "        dirName = f\"HMI/{caseNamesList[index]}\"\n",
    "\n",
    "        AIA_compare(\n",
    "            AIA = _dffluxCut.copy(),\n",
    "            PSP = dfIS.copy(), \n",
    "            AIA_id = \"HMI\",\n",
    "            PeriodMinMax = (24, 240),\n",
    "            delete = False,\n",
    "            showFig = False,\n",
    "            subfolderInfo = f\"{dirName}\",\n",
    "            showSpeed=True,\n",
    "            highlightRegion=False,\n",
    "            LOSPEED = LOSPEED, \n",
    "            HISPEED = HISPEED,\n",
    "            windDispList = [12* 60],\n",
    "            cadSelf = 12*60,\n",
    "            cadOther = 12*60\n",
    "                    )\n",
    "\n",
    "def superSummaryHMI():\n",
    "    ISStendTotal = (\n",
    "        dfIS.index[0].to_pydatetime(), \n",
    "        dfIS.index[-1].to_pydatetime()\n",
    "        )\n",
    "\n",
    "    allCases = []\n",
    "    Casetuple = namedtuple(\"Case\",\n",
    "                            [\"dirExtension\", \"isStend_t\", \"rsStend_t\"])\n",
    "\n",
    "    for index, rsTimes in enumerate(HMItimesList):\n",
    "        _isT = ISTimesList[index]\n",
    "        dirExtension = f\"HMI/{caseNamesList[index]}\"\n",
    "        allCases.append(\n",
    "            Casetuple(dirExtension, (_isT[0], _isT[1]),\n",
    "            (rsTimes[0], rsTimes[1])))\n",
    "\n",
    "    dfIS.columns = [\"PSP_\" + param for param in dfIS.columns]\n",
    "\n",
    "    for param in dfIS.columns:\n",
    "        plot_super_summary(\n",
    "            allCasesList = allCases,\n",
    "            longSpan = ISStendTotal,\n",
    "            wvlList=regLIST,\n",
    "            insituParam=param,\n",
    "            period=(24, 240),\n",
    "            regions=regLIST,\n",
    "            unsafeEMDDataPath = \"/home/diegodp/Documents/PhD/Paper_3/SolO_SDO_EUI/unsafe/ISSI/HMI/\",\n",
    "            SPCKernelName=\"psp\",\n",
    "            speedSuper= HISPEED,\n",
    "            speedSuperLow= LOSPEED,\n",
    "            speedAVG= AVGSPEED,\n",
    "            showFig=True,\n",
    "            figName=\"\", \n",
    "            gridRegions=(1,2, False, True))\n",
    "\n",
    "# compareHMI()\n",
    "superSummaryHMI()\n",
    "# TODO: Need to fix nrowsCols in signalHelpers"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Selecting ~ 10 hours of in situ observations with 14 switchbacks\n",
    "timeInsitu = (datetime(2018, 10, 31, 12), datetime(2018, 10, 31, 22))\n",
    "df_is_cut = df_is[timeInsitu[0]:timeInsitu[1]].copy()\n",
    "\n",
    "# Time in situ is one hour only?\n",
    "timeSbs = (datetime(2018,10,30,20), datetime(2018, 10, 30, 21))\n",
    "df_open = df_flux[\"ch_open_flux\"][timeSbs[0]:timeSbs[1]] \n",
    "df_bpoint = df_flux[\"ch_bpoint_flux\"][timeSbs[0]:timeSbs[1]] \n",
    "\n",
    "lcDic = {\n",
    "    \"open_flux\": df_171_cut.interpolate(),\n",
    "    \"bpoint_flux\": df_193_cut.interpolate(),\n",
    "}\n",
    "\n",
    "# Selecting ~ 10 hours of in situ observations\n",
    "timeInsitu = (datetime(2018, 11, 1, 12), datetime(2018, 11, 1, 20))\n",
    "df_is_copy = df_is[timeInsitu[0]:timeInsitu[1]].copy()\n",
    "\n",
    "timeSbs = (datetime(2018,10,30,20), datetime(2018, 10, 30, 21))\n",
    "df_cut_171 = df_171[timeSbs[0]:timeSbs[1]] \n",
    "df_cut_193 = df_193[timeSbs[0]:timeSbs[1]] \n",
    "\n",
    "for remDF, remLabel in zip((df_cut_171, df_cut_193), (\"171\", \"193\")):\n",
    "    AIA_compare(\n",
    "        AIA=remDF.copy(), PSP=df_is_copy.copy(), AIA_id=remLabel, \n",
    "        PeriodMinMax = PeriodMinMax, delete=DELETE, showFig=SHOWFIG,\n",
    "        subfolderInfo=\"SB_OtherSBs\", showSpeed=True, \n",
    "        highlightRegion = highlightRegion,\n",
    "        LOSPEED=df_is_copy[\"Vr\"].min(), HISPEED = df_is_copy[\"Vr\"].max()\n",
    "        )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Then produce summary plots"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}